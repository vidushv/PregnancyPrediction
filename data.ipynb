{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, json, sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "farm_april_aug = pd.read_excel('data/Daily_Data_AprilAug.xlsx', sheet_name='Sheet1')\n",
    "farm_aug_dec = pd.read_excel('data/Daily_Data_AugDec.xlsx', sheet_name='Sheet1')\n",
    "env_data = pd.read_csv('data/Environmental_data.csv')\n",
    "repro_data = pd.read_excel('data/ReproAllCows.XLS', sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing AfiFarm Data, Combining April - Dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = ['Date', 'ID', 'yeild', 'conductivity', 'fat',\n",
    "        'protein', 'lactose', 'scc', 'steps_per_hour', \n",
    "        'rest_time', 'rest_bout', 'rest_ratio', 'restlessness', \n",
    "        'rest_per_bout']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat1 = ['Date', 'Animal_ID', 'Yield (gr)', 'Conductivity', 'Fat (%)', 'Protein (%)', 'Lactose (%)', 'SCC (*1000/ml)',\n",
    " 'Activity (steps/hour)', 'RestTime (minutes)', 'RestBout (#)', 'RestRatio (%)', 'RestRestlessness', 'RestPerBout (minutes)']\n",
    "farm_april_aug = farm_april_aug[feat1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat2 = ['Date', 'Animal_ID', 'Yield(gr)', 'Conductivity', 'Fat(%)', 'Protein(%)', 'Lactose(%)', 'Avg_SCC(*1000/ml)',\n",
    " 'Activity(steps/hour)', 'RestTime(min)', 'RestBout', 'RestRatio(%)', 'RestRestlessness', 'RestPerBout(min)']\n",
    "farm_aug_dec = farm_aug_dec[feat2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "farm_april_aug.columns = feat\n",
    "farm_aug_dec.columns = feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(farm_april_aug.Date.iloc[0])\n",
    "print(farm_aug_dec.Date.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = farm_april_aug[['ID', 'Date']].drop_duplicates()\n",
    "farm_april_aug = pd.merge(temp, farm_april_aug, left_on=['ID', 'Date'], right_on=['ID', 'Date'])\n",
    "\n",
    "temp = farm_aug_dec[['ID', 'Date']].drop_duplicates()\n",
    "farm_aug_dec = pd.merge(temp, farm_aug_dec, left_on=['ID', 'Date'], right_on=['ID', 'Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Steps:\n",
    "    1. drop null columns\n",
    "    2. convert date to correct format\n",
    "'''\n",
    "def dateToInt1(x):\n",
    "    if '-' in str(x):\n",
    "        dmy = str(x).split(' ')[0].split('-')\n",
    "        return int(dmy[0])*365 + int(dmy[1])*30+int(dmy[2])\n",
    "    else:\n",
    "        dmy = str(x).split(' ')[0].split('/')\n",
    "        return int(dmy[2])*365 + int(dmy[0])*30+int(dmy[1])\n",
    "\n",
    "\n",
    "farm_april_aug = farm_april_aug.dropna()\n",
    "farm_aug_dec = farm_aug_dec.dropna()\n",
    "\n",
    "farm_april_aug['Date'] = farm_april_aug.Date.apply(lambda x: dateToInt1(x))\n",
    "farm_aug_dec['Date'] = farm_aug_dec.Date.apply(lambda x: dateToInt1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "farm_data = pd.concat([farm_april_aug, farm_aug_dec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "farm_data1 = farm_data.copy()\n",
    "farm_data1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Environmental Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Taking only columns H, I, J from the Environmental_data.csv\n",
    "'''\n",
    "env_data = env_data[['Date',\n",
    "                     'Temperature (S-THB 20427137:20353090-1), *C, RX \"3\" Pen 1',\n",
    "                     'RH (S-THB 20427137:20353090-2), %, RX \"3\" Pen 1',\n",
    "                     'Dew Point (S-THB 20427137:20353090-3), *C, RX \"3\" Pen 1']]\n",
    "env_data.columns = ['Date','temp','rh','dew_point']\n",
    "env_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Steps:\n",
    "    1. Removing rows with null values\n",
    "    2. Removing hours:minutes from the Date column,\n",
    "    3. Averaging out the temp, rh, dew_point for each day and storing 1 row per day\n",
    "\n",
    "'''\n",
    "\n",
    "# Step 1\n",
    "env_data1 = env_data.copy()\n",
    "env_data1 = env_data1.dropna()\n",
    "\n",
    "# Step 2\n",
    "env_data1['Date'] = env_data1.Date.apply(lambda x: x.split(' ')[0])\n",
    "\n",
    "# Step 3\n",
    "env_data1 = env_data1.groupby(['Date'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dateToInt1(x):\n",
    "    dmy = x.split('/')\n",
    "    return (int(dmy[2]) + 2000)*365 + int(dmy[0])*30 + int(dmy[1])\n",
    "\n",
    "env_data1['Date'] = env_data1.Date.apply(lambda x: dateToInt1(x))\n",
    "env_data1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Repro All Cows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Steps:\n",
    "    1. Extracting required columns \n",
    "    2. Removing rows with null values\n",
    "'''\n",
    "\n",
    "repro_data1 = repro_data.copy()\n",
    "repro_data1 = repro_data1[['ID', 'FDAT', 'LACT', 'DATB1', 'DIMB1', 'OUTB1']]\n",
    "repro_data1 = repro_data1.dropna()\n",
    "repro_data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Removing the rows where OUTB1 =='.' and not 'P' or 'O'\n",
    "'''\n",
    "\n",
    "repro_data1 = repro_data1[repro_data1['OUTB1']!='.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Converting date to integer\n",
    "'''\n",
    "\n",
    "def dateToInt2(x):\n",
    "    dmy = str(x).split(' ')[0].split('-')\n",
    "    return int(dmy[0])*365 + int(dmy[1])*30+int(dmy[2])\n",
    "\n",
    "repro_data1['FDAT'] = repro_data1['FDAT'].apply(lambda x: dateToInt2(x))\n",
    "repro_data1['DATB1'] = repro_data1['DATB1'].apply(lambda x: dateToInt2(x))\n",
    "repro_data1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Environment Data with ReproAllCows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(repro_data1, env_data1, left_on='DATB1', right_on='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Env, ReproAllCows, with AfiFarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.merge(farm_data1, data, left_on=['ID', 'Date'], right_on=['ID', 'Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "data needs to be loaded from true data not dummy\n",
    "'''\n",
    "y = data1[['OUTB1']]\n",
    "x = data1[['LACT', 'DIMB1', 'temp', 'rh', 'dew_point',\n",
    "          'yeild', 'conductivity', 'fat', 'restlessness',\n",
    "          'protein', 'lactose', 'scc', 'steps_per_hour', \n",
    "          'rest_time', 'rest_bout', 'rest_ratio', \n",
    "          'rest_per_bout']]\n",
    "\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x,y,test_size=0.2)\n",
    "\n",
    "for i in [10,100,1000]:\n",
    "    for j in [3, 4, 5]:\n",
    "        clf = RandomForestClassifier(n_estimators=i, max_depth=j, random_state=42)\n",
    "        clf.fit(xTrain,yTrain)\n",
    "        score1 = clf.score(xTest, yTest)\n",
    "        print(i, j, score1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "y = data1[['OUTB1']]\n",
    "x = data1[['LACT', 'DIMB1', 'temp', 'rh', 'dew_point',\n",
    "          'yeild', 'conductivity', 'fat', 'restlessness',\n",
    "          'protein', 'lactose', 'scc', 'steps_per_hour', \n",
    "          'rest_time', 'rest_bout', 'rest_ratio', \n",
    "          'rest_per_bout']]\n",
    "\n",
    "scaled_data = scaler.fit_transform(x)\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0, solver='liblinear').fit(xTrain, yTrain)\n",
    "score1 = clf.score(xTest, yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
